<template>
  <div class="audio-manager">
    <div class="file-upload">
      <input 
        type="file" 
        multiple 
        accept=".mp3"
        @change="handleFileUpload"
        ref="fileInput"
        style="display: none"
      />
      <button @click="$refs.fileInput.click()" class="btn btn-secondary">
        MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
      </button>
      <button 
        @click="startSimpleTranscription" 
        class="btn btn-primary"
        :disabled="audioFiles.length === 0 || isTranscribing"
      >
        {{ isTranscribing ? 'æ–‡å­—èµ·ã“ã—ä¸­...' : 'ç°¡æ˜“æ–‡å­—èµ·ã“ã—' }}
      </button>
      <button 
        @click="autoSyncFiles" 
        class="btn btn-secondary"
        :disabled="!canAutoSync"
      >
        {{ isSyncing ? 'åŒæœŸä¸­...' : 'è‡ªå‹•åŒæœŸ' }}
      </button>
      <select v-model="syncMethod" class="sync-method-select">
        <option value="correlation">ç›¸äº’ç›¸é–¢æ³•</option>
        <option value="timestamp">ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—</option>
        <option value="manual">æ‰‹å‹•èª¿æ•´ã®ã¿</option>
      </select>
    </div>
    
    <div v-if="syncResult" class="sync-info">
      <span>åŒæœŸæ‰‹æ³•: {{ syncMethodNames[syncResult.method] }}</span>
      <span v-if="syncResult.confidence">ä¿¡é ¼åº¦: {{ (syncResult.confidence * 100).toFixed(1) }}%</span>
    </div>

    <div class="audio-list">
      <div v-for="(file, index) in audioFiles" :key="file.id" class="audio-item">
        <div class="audio-info">
          <span class="file-name">{{ file.name }}</span>
          <span class="duration">{{ formatTime(file.duration) }}</span>
        </div>
        
        <div class="audio-controls">
          <!-- ä½ç½®åˆã‚ã›å®Œäº†ãƒˆã‚°ãƒ« -->
          <label class="fix-toggle" v-if="index > 0">
            <input 
              type="checkbox"
              :checked="file.isFixed"
              @change="toggleFixed(index)"
            />
            <span>{{ file.isFixed ? 'ğŸ”’' : 'ğŸ”“' }} ä½ç½®å›ºå®š</span>
          </label>
          
          <!-- ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´UI -->
          <div class="offset-control" :class="{ disabled: file.isFixed || index === 0 }">
            <label>ã‚ªãƒ•ã‚»ãƒƒãƒˆ:</label>
            <input 
              type="number"
              :value="index === 0 ? 0 : file.offset"
              @input="updateOffsetDirect(index, $event)"
              :disabled="file.isFixed || index === 0"
              step="0.01"
              class="offset-input"
            />
            <span>ç§’</span>
            
            <!-- å¾®èª¿æ•´ãƒœã‚¿ãƒ³ -->
            <div class="offset-buttons" v-if="index > 0 && !file.isFixed">
              <button @click="adjustOffset(index, -1)" class="btn btn-tiny">â—€ -1s</button>
              <button @click="adjustOffset(index, -0.1)" class="btn btn-tiny">â—€ -0.1s</button>
              <button @click="adjustOffset(index, -0.01)" class="btn btn-tiny">â—€ -0.01s</button>
              <span class="separator">|</span>
              <button @click="adjustOffset(index, 0.01)" class="btn btn-tiny">â–¶ +0.01s</button>
              <button @click="adjustOffset(index, 0.1)" class="btn btn-tiny">â–¶ +0.1s</button>
              <button @click="adjustOffset(index, 1)" class="btn btn-tiny">â–¶ +1s</button>
            </div>
          </div>
          
          <label>
            éŸ³é‡:
            <input 
              type="range" 
              :min="0" 
              :max="100" 
              :value="file.volume * 100"
              @input="updateVolume(index, $event)"
              class="volume-slider"
            />
          </label>
          
          <button 
            @click="toggleMute(index)"
            class="btn btn-small"
            :class="{ muted: file.muted }"
          >
            {{ file.muted ? 'ğŸ”‡' : 'ğŸ”Š' }}
          </button>
          
          <button @click="removeFile(index)" class="btn btn-small btn-danger">
            å‰Šé™¤
          </button>
        </div>
        
        <!-- æ³¢å½¢è¡¨ç¤ºã‚¨ãƒªã‚¢ -->
        <div class="waveform-container">
          <div class="waveform-info">
            <span class="offset-label">ã‚ªãƒ•ã‚»ãƒƒãƒˆ: {{ file.offset.toFixed(2) }}ç§’</span>
            <span v-if="file.offset < 0" class="offset-label">ï¼ˆ{{ Math.abs(file.offset).toFixed(2) }}ç§’å…ˆè¡Œï¼‰</span>
          </div>
          <div :id="`waveform-${file.id}`" class="waveform"></div>
          <div v-if="index > 0" class="waveform-sync-controls">
            <button @click="showWaveformComparison(index)" class="btn btn-tiny" :disabled="file.isFixed">
              ğŸ” æ³¢å½¢æ¯”è¼ƒ
            </button>
          </div>
        </div>
        
        <audio 
          :ref="el => audioRefs[index] = el"
          :src="file.url"
          @loadedmetadata="handleMetadata(index, $event)"
          @timeupdate="handleTimeUpdate"
        />
      </div>
    </div>

    <div v-if="audioFiles.length > 0" class="playback-controls">
      <button @click="seekBackward" class="btn btn-small">âª</button>
      <button @click="togglePlayPause" class="btn btn-primary">
        {{ isPlaying ? 'â¸ï¸' : 'â–¶ï¸' }}
      </button>
      <button @click="seekForward" class="btn btn-small">â©</button>
      
      <span class="time-display">
        {{ formatTime(currentTime) }} / {{ formatTime(maxDuration) }}
      </span>
      
      <label>
        é€Ÿåº¦:
        <select v-model="playbackRate" @change="updatePlaybackRate">
          <option value="0.5">0.5x</option>
          <option value="0.75">0.75x</option>
          <option value="1">1.0x</option>
          <option value="1.25">1.25x</option>
          <option value="1.5">1.5x</option>
          <option value="2">2.0x</option>
        </select>
      </label>
      
      <input 
        type="range"
        :min="0"
        :max="maxDuration"
        :value="currentTime"
        @input="seek"
        class="seek-bar"
      />
    </div>
    
    <div v-if="transcriptionStatus" class="transcription-status">
      {{ transcriptionStatus }}
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, watch, onMounted, onUnmounted, nextTick } from 'vue';
import type { AudioFile, Segment } from '../types';
import { findBestOffset, loadAudioBuffer } from '../utils/audioSync';
import WaveSurfer from 'wavesurfer.js';

const props = defineProps<{
  audioFiles: AudioFile[]
}>();

const emit = defineEmits<{
  update: [files: AudioFile[]]
  timeUpdate: [time: number]
  addSegment: [segment: Segment]
}>();

const audioRefs = ref<(HTMLAudioElement | null)[]>([]);
const isPlaying = ref(false);
const currentTime = ref(0);
const playbackRate = ref('1');
const isTranscribing = ref(false);
const isSyncing = ref(false);
const syncMethod = ref('correlation');
const syncResult = ref<{ method: string; confidence?: number } | null>(null);
const transcriptionStatus = ref('');
const waveforms = ref<Map<string, any>>(new Map());
const showingComparison = ref<string | null>(null);

const syncMethodNames: Record<string, string> = {
  correlation: 'ç›¸äº’ç›¸é–¢æ³•',
  timestamp: 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹',
  manual: 'æ‰‹å‹•èª¿æ•´'
};

const maxDuration = computed(() => {
  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é–‹å§‹æ™‚åˆ»ã‚’è¨ˆç®—
  const globalStartTimes = getGlobalStartTimes();
  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ‚äº†æ™‚åˆ»ã‚’è¨ˆç®—
  const endTimes = props.audioFiles.map((f, i) => globalStartTimes[i] + f.duration);
  return Math.max(...endTimes, 0);
});

const canAutoSync = computed(() => {
  if (props.audioFiles.length < 2 || isSyncing.value) return false;
  // å…ˆé ­ä»¥å¤–ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒFIXæ¸ˆã¿ãªã‚‰è‡ªå‹•åŒæœŸä¸å¯
  const nonFirstFiles = props.audioFiles.slice(1);
  return !nonFirstFiles.every(f => f.isFixed);
});

const handleFileUpload = async (event: Event) => {
  const input = event.target as HTMLInputElement;
  if (!input.files) return;
  
  const newFiles: AudioFile[] = [];
  for (const file of Array.from(input.files)) {
    if (file.type !== 'audio/mpeg') continue;
    
    const audioFile: AudioFile = {
      id: `file_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      name: file.name,
      blob: file, // ãƒ¡ãƒ¢ãƒªä¸Šã§ã®ã¿ä¿æŒ
      arrayBuffer: undefined, // ä¿å­˜æ™‚ã«å¤‰æ›
      url: URL.createObjectURL(file),
      duration: 0,
      offset: 0,
      volume: 1,
      muted: false,
      isFixed: false
    };
    newFiles.push(audioFile);
  }
  
  emit('update', [...props.audioFiles, ...newFiles]);
  // æ³¢å½¢ã®åˆæœŸåŒ–ã¯watchã§è‡ªå‹•çš„ã«è¡Œã‚ã‚Œã‚‹
};

const handleMetadata = (index: number, event: Event) => {
  const audio = event.target as HTMLAudioElement;
  const files = [...props.audioFiles];
  files[index].duration = audio.duration;
  emit('update', files);
};

const updateOffset = (index: number, event: Event) => {
  const input = event.target as HTMLInputElement;
  const files = [...props.audioFiles];
  files[index].offset = parseFloat(input.value);
  emit('update', files);
};

const updateOffsetDirect = (index: number, event: Event) => {
  if (index === 0) return; // æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯åŸºæº–ãªã®ã§å¤‰æ›´ä¸å¯
  const input = event.target as HTMLInputElement;
  const files = [...props.audioFiles];
  files[index].offset = parseFloat(input.value) || 0;
  emit('update', files);
};

const adjustOffset = (index: number, delta: number) => {
  if (index === 0) return;
  const files = [...props.audioFiles];
  files[index].offset = Math.round((files[index].offset + delta) * 100) / 100; // 0.01ç§’å˜ä½ã«ä¸¸ã‚
  emit('update', files);
};

const toggleFixed = (index: number) => {
  const files = [...props.audioFiles];
  files[index].isFixed = !files[index].isFixed;
  emit('update', files);
};

const updateVolume = (index: number, event: Event) => {
  const input = event.target as HTMLInputElement;
  const files = [...props.audioFiles];
  files[index].volume = parseFloat(input.value) / 100;
  emit('update', files);
  
  if (audioRefs.value[index]) {
    audioRefs.value[index]!.volume = files[index].volume;
  }
};

const toggleMute = (index: number) => {
  const files = [...props.audioFiles];
  files[index].muted = !files[index].muted;
  emit('update', files);
  
  if (audioRefs.value[index]) {
    audioRefs.value[index]!.muted = files[index].muted;
  }
};

const removeFile = (index: number) => {
  const files = [...props.audioFiles];
  const fileId = files[index].id;
  
  // æ³¢å½¢ã‚’ç ´æ£„
  if (waveforms.value.has(fileId)) {
    waveforms.value.get(fileId).destroy();
    waveforms.value.delete(fileId);
  }
  
  URL.revokeObjectURL(files[index].url!);
  files.splice(index, 1);
  emit('update', files);
};

const togglePlayPause = () => {
  if (isPlaying.value) {
    pauseAll();
  } else {
    playAll();
  }
};

const playAll = () => {
  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
  const globalStartTimes = getGlobalStartTimes();
  
  audioRefs.value.forEach((audio, index) => {
    if (!audio) return;
    const file = props.audioFiles[index];
    
    // ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚é–“è»¸ä¸Šã§ã®ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®é–‹å§‹æ™‚åˆ»
    const globalStartTime = globalStartTimes[index];
    
    // ç¾åœ¨ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ã‹ã‚‰ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«æ™‚åˆ»ã‚’è¨ˆç®—
    const localTime = currentTime.value - globalStartTime;
    
    // ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã é–‹å§‹ã—ã¦ã„ãªã„å ´åˆã¯å†ç”Ÿã—ãªã„
    if (localTime < 0) {
      audio.pause();
      audio.currentTime = 0;
      return;
    }
    
    // ãƒ•ã‚¡ã‚¤ãƒ«ãŒçµ‚äº†ã—ã¦ã„ã‚‹å ´åˆã¯å†ç”Ÿã—ãªã„
    if (localTime >= audio.duration) {
      audio.pause();
      return;
    }
    
    // æ­£å¸¸ãªç¯„å›²å†…ãªã‚‰å†ç”Ÿ
    audio.currentTime = localTime;
    audio.volume = file.volume;
    audio.muted = file.muted;
    audio.playbackRate = parseFloat(playbackRate.value);
    audio.play();
  });
  isPlaying.value = true;
};

const pauseAll = () => {
  audioRefs.value.forEach(audio => {
    if (audio) audio.pause();
  });
  isPlaying.value = false;
};

const seek = (event: Event) => {
  const input = event.target as HTMLInputElement;
  currentTime.value = parseFloat(input.value);
  
  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
  const globalStartTimes = getGlobalStartTimes();
  
  audioRefs.value.forEach((audio, index) => {
    if (!audio) return;
    const file = props.audioFiles[index];
    
    // ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚é–“è»¸ä¸Šã§ã®ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®é–‹å§‹æ™‚åˆ»
    const globalStartTime = globalStartTimes[index];
    
    // ç¾åœ¨ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ã‹ã‚‰ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«æ™‚åˆ»ã‚’è¨ˆç®—
    const localTime = currentTime.value - globalStartTime;
    
    // ç¯„å›²å†…ã«ã‚¯ãƒªãƒƒãƒ—
    audio.currentTime = Math.max(0, Math.min(localTime, audio.duration));
  });
};

const seekForward = () => {
  currentTime.value = Math.min(maxDuration.value, currentTime.value + 5);
  seek({ target: { value: currentTime.value.toString() } } as any);
};

const seekBackward = () => {
  currentTime.value = Math.max(0, currentTime.value - 5);
  seek({ target: { value: currentTime.value.toString() } } as any);
};

const updatePlaybackRate = () => {
  audioRefs.value.forEach(audio => {
    if (audio) audio.playbackRate = parseFloat(playbackRate.value);
  });
};

const handleTimeUpdate = () => {
  if (audioRefs.value.length === 0) return;
  
  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
  const globalStartTimes = getGlobalStartTimes();
  
  // ç¾åœ¨å†ç”Ÿä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
  for (let i = 0; i < audioRefs.value.length; i++) {
    const audio = audioRefs.value[i];
    if (audio && !audio.paused) {
      const file = props.audioFiles[i];
      const globalStartTime = globalStartTimes[i];
      // ãƒ­ãƒ¼ã‚«ãƒ«æ™‚åˆ»ã‹ã‚‰ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ã¸å¤‰æ›
      currentTime.value = audio.currentTime + globalStartTime;
      emit('timeUpdate', currentTime.value);
      break;
    }
  }
};

const startSimpleTranscription = async () => {
  if (props.audioFiles.length === 0) return;
  
  isTranscribing.value = true;
  transcriptionStatus.value = 'éŸ³å£°èªè­˜ã‚’æº–å‚™ä¸­...';
  
  try {
    // ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
    const dummySegments: Segment[] = [
      {
        id: Date.now().toString() + '_1',
        start: 0,
        end: 10,
        text: '[ã“ã“ã«æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„]',
        speaker: '1'
      },
      {
        id: Date.now().toString() + '_2',
        start: 10,
        end: 20,
        text: '[éŸ³å£°ã‚’èããªãŒã‚‰æ‰‹å‹•ã§æ–‡å­—èµ·ã“ã—ã‚’ã—ã¦ãã ã•ã„]',
        speaker: '2'
      },
      {
        id: Date.now().toString() + '_3',
        start: 20,
        end: 30,
        text: '[Web Speech APIã®åˆ¶é™ã«ã‚ˆã‚Šã€ãƒã‚¤ã‚¯å…¥åŠ›ãŒå¿…è¦ã§ã™]',
        speaker: '1'
      }
    ];
    
    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
    dummySegments.forEach(segment => {
      emit('addSegment', segment);
    });
    
    transcriptionStatus.value = 'æ‰‹å‹•æ–‡å­—èµ·ã“ã—ç”¨ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚éŸ³å£°ã‚’èããªãŒã‚‰ç·¨é›†ã—ã¦ãã ã•ã„ã€‚';
    
    // ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°èªè­˜ã‚’è©¦ã¿ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const confirmMic = confirm('ãƒã‚¤ã‚¯ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™ã‹ï¼Ÿ\nï¼ˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã—ãªãŒã‚‰ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®éŸ³ã‚’ãƒã‚¤ã‚¯ã§æ‹¾ã„ã¾ã™ï¼‰');
      
      if (confirmMic) {
        await startMicrophoneTranscription();
      }
    }
    
  } catch (error) {
    console.error('Transcription error:', error);
    transcriptionStatus.value = 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚';
  } finally {
    isTranscribing.value = false;
    setTimeout(() => {
      transcriptionStatus.value = '';
    }, 5000);
  }
};

const startMicrophoneTranscription = async () => {
  const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
  
  if (!SpeechRecognition) {
    transcriptionStatus.value = 'ãƒ–ãƒ©ã‚¦ã‚¶ãŒéŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“';
    return;
  }
  
  const recognition = new SpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = true;
  
  // è¤‡æ•°ã®è¨€èªã‚’è©¦ã™
  const languages = ['ja-JP', 'ja', 'en-US', 'en'];
  let currentLangIndex = 0;
  
  recognition.lang = languages[currentLangIndex];
  
  recognition.onresult = (event: any) => {
    for (let i = event.resultIndex; i < event.results.length; i++) {
      if (event.results[i].isFinal) {
        const segment: Segment = {
          id: Date.now().toString(),
          start: currentTime.value,
          end: currentTime.value + 5,
          text: event.results[i][0].transcript,
          speaker: '1'
        };
        emit('addSegment', segment);
        transcriptionStatus.value = `èªè­˜: ${event.results[i][0].transcript}`;
      }
    }
  };
  
  recognition.onerror = (event: any) => {
    console.log('Recognition error:', event.error);
    
    if (event.error === 'language-not-supported' && currentLangIndex < languages.length - 1) {
      currentLangIndex++;
      recognition.lang = languages[currentLangIndex];
      transcriptionStatus.value = `è¨€èªã‚’åˆ‡ã‚Šæ›¿ãˆä¸­: ${languages[currentLangIndex]}`;
      recognition.start();
    } else {
      transcriptionStatus.value = `éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`;
    }
  };
  
  recognition.onend = () => {
    transcriptionStatus.value = 'ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°èªè­˜ã‚’çµ‚äº†ã—ã¾ã—ãŸ';
  };
  
  // éŸ³å£°ã‚’å†ç”Ÿã—ã¦ã‹ã‚‰ãƒã‚¤ã‚¯éŒ²éŸ³ã‚’é–‹å§‹
  pauseAll();
  currentTime.value = 0;
  playAll();
  
  transcriptionStatus.value = 'ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’èªè­˜ä¸­...ï¼ˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®éŸ³ã‚’ãƒã‚¤ã‚¯ã«è¿‘ã¥ã‘ã¦ãã ã•ã„ï¼‰';
  recognition.start();
  
  // 30ç§’å¾Œã«åœæ­¢
  setTimeout(() => {
    recognition.stop();
    pauseAll();
  }, 30000);
};

const autoSyncFiles = async () => {
  if (props.audioFiles.length < 2) return;
  
  isSyncing.value = true;
  syncResult.value = null;
  
  try {
    const files = [...props.audioFiles];
    let totalConfidence = 0;
    let successCount = 0;
    
    if (syncMethod.value === 'correlation') {
      // ç›¸äº’ç›¸é–¢æ³•
      const referenceBuffer = await loadAudioBuffer(props.audioFiles[0].blob);
      const newOffsets: number[] = [0];
      
      for (let i = 1; i < props.audioFiles.length; i++) {
        // FIXæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
        if (files[i].isFixed) {
          newOffsets.push(files[i].offset);
          console.log(`File ${i}: Skipped (Fixed)`);
          continue;
        }
        
        const targetBuffer = await loadAudioBuffer(props.audioFiles[i].blob);
        const result = await findBestOffset(referenceBuffer, targetBuffer);
        newOffsets.push(result.offset);
        totalConfidence += result.confidence;
        successCount++;
        
        console.log(`File ${i}: Offset=${result.offset.toFixed(2)}s, Confidence=${(result.confidence * 100).toFixed(1)}%`);
      }
      
      files.forEach((file, index) => {
        if (!file.isFixed) {
          file.offset = Math.round(newOffsets[index] * 100) / 100; // 0.01ç§’å˜ä½ã«ä¿®æ­£
        }
      });
      
      syncResult.value = {
        method: 'correlation',
        confidence: successCount > 0 ? totalConfidence / successCount : 0
      };
      
    } else if (syncMethod.value === 'timestamp') {
      // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
      alert('ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®åŒæœŸã¯æœªå®Ÿè£…ã§ã™ã€‚ç›¸äº’ç›¸é–¢æ³•ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚');
      return;
      
    } else {
      // æ‰‹å‹•èª¿æ•´ã®ã¿
      syncResult.value = { method: 'manual' };
      alert('æ‰‹å‹•ã§å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚');
      return;
    }
    
    emit('update', files);
    alert(`è‡ªå‹•åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆ${syncMethodNames[syncMethod.value]}ï¼‰ã€‚å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§å¾®èª¿æ•´ã—ã¦ãã ã•ã„ã€‚`);
  } catch (error) {
    console.error('Auto-sync error:', error);
    alert('è‡ªå‹•åŒæœŸã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§èª¿æ•´ã—ã¦ãã ã•ã„ã€‚');
  } finally {
    isSyncing.value = false;
  }
};

const formatTime = (seconds: number): string => {
  if (!seconds || isNaN(seconds)) return '00:00';
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
};

const initWaveform = async (file: AudioFile) => {
  if (!file.url) return;
  
  // æ—¢å­˜ã®æ³¢å½¢ã‚’å¿…ãšç ´æ£„
  if (waveforms.value.has(file.id)) {
    console.log(`Destroying existing waveform for ${file.id}`);
    const existingWaveform = waveforms.value.get(file.id);
    existingWaveform.destroy();
    waveforms.value.delete(file.id);
  }
  
  await nextTick();
  
  const container = document.querySelector(`#waveform-${file.id}`) as HTMLElement;
  if (!container) {
    console.warn(`Container not found for ${file.id}`);
    return;
  }
  
  // ã‚³ãƒ³ãƒ†ãƒŠã®ä¸­èº«ã‚’ã‚¯ãƒªã‚¢
  container.innerHTML = '';
  
  try {
    // ã‚³ãƒ³ãƒ†ãƒŠã®å¹…ã‚’å–å¾—
    const containerWidth = container.offsetWidth || 800;
    
    // 0.01ç§’ = 1ãƒ”ã‚¯ã‚»ãƒ«ã«è¨­å®š
    const minPxPerSec = 100; // 1ç§’ = 100ãƒ”ã‚¯ã‚»ãƒ« (0.01ç§’ = 1ãƒ”ã‚¯ã‚»ãƒ«)
    
    // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ä»˜ãã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
    // const paddedUrl = await createPaddedAudio(file);
    const paddedUrl = null; // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã—ã¦å•é¡Œã‚’åˆ‡ã‚Šåˆ†ã‘
    
    const wavesurfer = WaveSurfer.create({
      container: container,
      waveColor: '#4CAF50',
      progressColor: '#2196F3',
      cursorColor: '#FF5722',
      height: 60,
      normalize: true,
      backend: 'WebAudio',
      interact: false, // æ³¢å½¢è‡ªä½“ã¯ã‚¯ãƒªãƒƒã‚¯ä¸å¯
      minPxPerSec: minPxPerSec, // æœ€å°ãƒ”ã‚¯ã‚»ãƒ«/ç§’
      scrollParent: true, // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’æœ‰åŠ¹åŒ–
      barWidth: 1, // ãƒãƒ¼ã®å¹…ã‚’1ãƒ”ã‚¯ã‚»ãƒ«ã«
      barGap: 0, // ã‚®ãƒ£ãƒƒãƒ—ã‚’ãªãã—ã¦ç¶™ç›®ãªãè¡¨ç¤º
      barHeight: 1 // ãƒãƒ¼ã®é«˜ã•ã‚’æ­£è¦åŒ–
    });
    
    await wavesurfer.load(paddedUrl || file.url);
    waveforms.value.set(file.id, wavesurfer);
    
    // å†ç”Ÿä½ç½®ã‚’åŒæœŸ
    wavesurfer.on('ready', () => {
      updateWaveformPosition(file.id);
    });
  } catch (error) {
    console.error('Failed to initialize waveform:', error);
  }
};

const updateWaveformPosition = (fileId: string) => {
  const wavesurfer = waveforms.value.get(fileId);
  if (!wavesurfer) return;
  
  const file = props.audioFiles.find(f => f.id === fileId);
  if (!file) return;
  
  const fileIndex = props.audioFiles.indexOf(file);
  const globalStartTimes = getGlobalStartTimes();
  const globalStartTime = globalStartTimes[fileIndex];
  
  // ãƒ­ãƒ¼ã‚«ãƒ«æ™‚åˆ»ã‚’è¨ˆç®—
  const localTime = currentTime.value - globalStartTime;
  
  // æ³¢å½¢ä¸Šã®ä½ç½®ã‚’æ›´æ–°
  if (localTime >= 0 && localTime <= file.duration) {
    const progress = localTime / file.duration;
    if (!isNaN(progress)) {
      wavesurfer.seekTo(progress);
    }
  } else {
    wavesurfer.seekTo(0);
  }
};

const showWaveformComparison = (index: number) => {
  const targetFile = props.audioFiles[index];
  const referenceFile = props.audioFiles[0];
  
  if (showingComparison.value === targetFile.id) {
    showingComparison.value = null;
    // æ³¢å½¢ã‚’å†ä½œæˆã—ã¦å…ƒã®è‰²ã«æˆ»ã™
    recreateWaveform(referenceFile);
    recreateWaveform(targetFile);
    return;
  }
  
  showingComparison.value = targetFile.id;
  
  // æ³¢å½¢ã‚’å†ä½œæˆã—ã¦è‰²ã‚’å¤‰æ›´
  recreateWaveform(referenceFile, '#FF9800', '#FF5722');
  recreateWaveform(targetFile, '#2196F3', '#1976D2');
  
  // 3ç§’å¾Œã«å…ƒã«æˆ»ã™
  setTimeout(() => {
    if (showingComparison.value === targetFile.id) {
      recreateWaveform(referenceFile);
      recreateWaveform(targetFile);
      showingComparison.value = null;
    }
  }, 3000);
};

const recreateWaveform = async (file: AudioFile, waveColor: string = '#4CAF50', progressColor: string = '#2196F3') => {
  if (!file.url) return;
  
  // æ—¢å­˜ã®æ³¢å½¢ã‚’ç ´æ£„
  if (waveforms.value.has(file.id)) {
    waveforms.value.get(file.id).destroy();
    waveforms.value.delete(file.id);
  }
  
  await nextTick();
  
  const container = document.querySelector(`#waveform-${file.id}`) as HTMLElement;
  if (!container) return;
  
  // ã‚³ãƒ³ãƒ†ãƒŠã®ä¸­èº«ã‚’ã‚¯ãƒªã‚¢
  container.innerHTML = '';
  
  try {
    // ã‚³ãƒ³ãƒ†ãƒŠã®å¹…ã‚’å–å¾—
    const containerWidth = container.offsetWidth || 800;
    
    // 0.01ç§’ = 1ãƒ”ã‚¯ã‚»ãƒ«ã«è¨­å®š
    const minPxPerSec = 100; // 1ç§’ = 100ãƒ”ã‚¯ã‚»ãƒ« (0.01ç§’ = 1ãƒ”ã‚¯ã‚»ãƒ«)
    
    // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ä»˜ãã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
    // const paddedUrl = await createPaddedAudio(file);
    const paddedUrl = null; // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
    
    const wavesurfer = WaveSurfer.create({
      container: container,
      waveColor: waveColor,
      progressColor: progressColor,
      cursorColor: '#FF5722',
      height: 60,
      normalize: true,
      backend: 'WebAudio',
      interact: false,
      minPxPerSec: minPxPerSec,
      scrollParent: true,
      barWidth: 1,
      barGap: 0,
      barHeight: 1
    });
    
    await wavesurfer.load(paddedUrl || file.url);
    waveforms.value.set(file.id, wavesurfer);
    
    // ç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚’åæ˜ 
    const audioIndex = props.audioFiles.indexOf(file);
    const audio = audioRefs.value[audioIndex];
    if (audio) {
      const progress = audio.currentTime / audio.duration;
      if (!isNaN(progress)) {
        wavesurfer.seekTo(progress);
      }
    }
  } catch (error) {
    console.error('Failed to recreate waveform:', error);
  }
};

// ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ä»˜ãã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
const createPaddedAudio = async (file: AudioFile): Promise<string | null> => {
  if (!file.blob) return null;
  
  try {
    const audioContext = new AudioContext();
    const arrayBuffer = await file.blob.arrayBuffer();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    
    // ã‚°ãƒ­ãƒ¼ãƒãƒ«é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
    const globalStartTimes = getGlobalStartTimes();
    const fileIndex = props.audioFiles.indexOf(file);
    const globalStartTime = globalStartTimes[fileIndex];
    
    // ç·æ™‚é–“ã‚’è¨ˆç®—
    const totalGlobalDuration = maxDuration.value;
    
    // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®è¨ˆç®—
    const startPadding = globalStartTime; // å‰ã®ç„¡éŸ³éƒ¨åˆ†
    const endPadding = Math.max(0, totalGlobalDuration - (globalStartTime + file.duration)); // å¾Œã‚ã®ç„¡éŸ³éƒ¨åˆ†
    
    // æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
    const sampleRate = audioBuffer.sampleRate;
    const totalBufferDuration = startPadding + audioBuffer.duration + endPadding;
    const totalLength = Math.ceil(totalBufferDuration * sampleRate);
    const paddedBuffer = audioContext.createBuffer(
      audioBuffer.numberOfChannels,
      totalLength,
      sampleRate
    );
    
    // å„ãƒãƒ£ãƒ³ãƒãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
    for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
      const channelData = paddedBuffer.getChannelData(channel);
      const originalData = audioBuffer.getChannelData(channel);
      const startOffset = Math.floor(startPadding * sampleRate);
      
      // å…ƒã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ãªä½ç½®ã«ã‚³ãƒ”ãƒ¼
      for (let i = 0; i < originalData.length; i++) {
        if (startOffset + i < channelData.length) {
          channelData[startOffset + i] = originalData[i];
        }
      }
      // å‰å¾Œã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ†ã¯0ï¼ˆç„¡éŸ³ï¼‰ã®ã¾ã¾
    }
    
    // AudioBufferã‚’Blobã«å¤‰æ›
    const offlineContext = new OfflineAudioContext(
      paddedBuffer.numberOfChannels,
      paddedBuffer.length,
      paddedBuffer.sampleRate
    );
    const source = offlineContext.createBufferSource();
    source.buffer = paddedBuffer;
    source.connect(offlineContext.destination);
    source.start();
    
    const renderedBuffer = await offlineContext.startRendering();
    
    // WAVå½¢å¼ã«å¤‰æ›
    const wav = audioBufferToWav(renderedBuffer);
    const blob = new Blob([wav], { type: 'audio/wav' });
    return URL.createObjectURL(blob);
  } catch (error) {
    console.error('Failed to create padded audio:', error);
    return null;
  }
};

// AudioBufferã‚’WAVå½¢å¼ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
const audioBufferToWav = (buffer: AudioBuffer): ArrayBuffer => {
  const length = buffer.length * buffer.numberOfChannels * 2 + 44;
  const arrayBuffer = new ArrayBuffer(length);
  const view = new DataView(arrayBuffer);
  const channels: Float32Array[] = [];
  let offset = 0;
  let pos = 0;
  
  // å„ãƒãƒ£ãƒ³ãƒãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
  for (let i = 0; i < buffer.numberOfChannels; i++) {
    channels.push(buffer.getChannelData(i));
  }
  
  // WAVãƒ˜ãƒƒãƒ€ã‚’æ›¸ãè¾¼ã¿
  const setString = (offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };
  
  setString(pos, 'RIFF'); pos += 4;
  view.setUint32(pos, length - 8, true); pos += 4;
  setString(pos, 'WAVE'); pos += 4;
  setString(pos, 'fmt '); pos += 4;
  view.setUint32(pos, 16, true); pos += 4;
  view.setUint16(pos, 1, true); pos += 2;
  view.setUint16(pos, buffer.numberOfChannels, true); pos += 2;
  view.setUint32(pos, buffer.sampleRate, true); pos += 4;
  view.setUint32(pos, buffer.sampleRate * buffer.numberOfChannels * 2, true); pos += 4;
  view.setUint16(pos, buffer.numberOfChannels * 2, true); pos += 2;
  view.setUint16(pos, 16, true); pos += 2;
  setString(pos, 'data'); pos += 4;
  view.setUint32(pos, length - pos - 4, true); pos += 4;
  
  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
  const volume = 0x7FFF;
  for (let i = 0; i < buffer.length; i++) {
    for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
      const sample = Math.max(-1, Math.min(1, channels[channel][i]));
      view.setInt16(pos, sample * volume, true);
      pos += 2;
    }
  }
  
  return arrayBuffer;
};

const seekToTime = (time: number) => {
  currentTime.value = time;
  seek({ target: { value: time.toString() } } as any);
  if (isPlaying.value) {
    pauseAll();
    setTimeout(() => playAll(), 100);
  }
};

// å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é–‹å§‹æ™‚åˆ»ã‚’è¨ˆç®—
const getGlobalStartTimes = () => {
  const startTimes: number[] = [];
  
  // ç¬¬1éŸ³å£°ã¯å¸¸ã«åŸºæº–
  startTimes[0] = 0;
  
  // ç¬¬2éŸ³å£°ä»¥é™ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆãŒè² ã®å ´åˆã€å…¨ä½“ã‚’èª¿æ•´
  for (let i = 1; i < props.audioFiles.length; i++) {
    const offset = props.audioFiles[i].offset;
    if (offset < 0) {
      // è² ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã®å ´åˆã€ç¬¬1éŸ³å£°ã‚’ãã®åˆ†é…ã‚‰ã›ã‚‹
      startTimes[0] = Math.max(startTimes[0], -offset);
      startTimes[i] = 0;
    } else {
      startTimes[i] = offset;
    }
  }
  
  return startTimes;
};

// æœ€å°ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆäº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰
const getMinOffset = () => {
  const globalStartTimes = getGlobalStartTimes();
  return Math.min(...globalStartTimes);
};

// å†ç”Ÿä½ç½®ãŒæ›´æ–°ã•ã‚ŒãŸã‚‰æ³¢å½¢ã‚‚æ›´æ–°
watch(() => currentTime.value, () => {
  props.audioFiles.forEach(file => {
    updateWaveformPosition(file.id);
  });
});

// ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰æ³¢å½¢ã‚’åˆæœŸåŒ–
watch(() => props.audioFiles, async (newFiles, oldFiles) => {
  // æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ³¢å½¢ã‚’åˆæœŸåŒ–
  for (const file of newFiles) {
    if (!waveforms.value.has(file.id) && file.url) {
      await initWaveform(file);
    }
  }
  
  // å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ³¢å½¢ã‚’ç ´æ£„
  if (oldFiles) {
    for (const oldFile of oldFiles) {
      if (!newFiles.find(f => f.id === oldFile.id)) {
        if (waveforms.value.has(oldFile.id)) {
          waveforms.value.get(oldFile.id).destroy();
          waveforms.value.delete(oldFile.id);
        }
      }
    }
  }
}, { deep: true, immediate: true }); // immediate: trueã§åˆå›ãƒã‚¦ãƒ³ãƒˆæ™‚ã‚‚å®Ÿè¡Œ

onUnmounted(() => {
  // ã™ã¹ã¦ã®æ³¢å½¢ã‚’ç ´æ£„
  waveforms.value.forEach(wavesurfer => {
    wavesurfer.destroy();
  });
  waveforms.value.clear();
});

defineExpose({
  seekToTime
});
</script>

<style scoped>
.audio-manager {
  background: white;
  border-radius: 8px;
  padding: 1.5rem;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

.file-upload {
  margin-bottom: 1.5rem;
  display: flex;
  gap: 1rem;
  flex-wrap: wrap;
}

.audio-list {
  margin-bottom: 1.5rem;
}

.audio-item {
  border: 1px solid #e0e0e0;
  border-radius: 4px;
  padding: 1rem;
  margin-bottom: 1rem;
}

.audio-info {
  display: flex;
  justify-content: space-between;
  margin-bottom: 0.5rem;
  font-weight: bold;
}

.audio-controls {
  display: flex;
  align-items: center;
  gap: 1rem;
  flex-wrap: wrap;
}

.audio-controls label {
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.offset-slider,
.volume-slider {
  width: 100px;
}

.playback-controls {
  display: flex;
  align-items: center;
  gap: 1rem;
  padding: 1rem;
  background: #f5f5f5;
  border-radius: 4px;
}

.seek-bar {
  flex: 1;
}

.time-display {
  font-family: monospace;
}

.transcription-status {
  margin-top: 1rem;
  padding: 0.75rem;
  background: #e3f2fd;
  border: 1px solid #90caf9;
  border-radius: 4px;
  color: #1976d2;
  font-size: 0.875rem;
}

.btn {
  padding: 0.5rem 1rem;
  border: none;
  border-radius: 4px;
  cursor: pointer;
  background: #95a5a6;
  color: white;
  transition: background 0.3s;
}

.btn:hover:not(:disabled) {
  background: #7f8c8d;
}

.btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.btn-primary {
  background: #3498db;
}

.btn-primary:hover:not(:disabled) {
  background: #2980b9;
}

.btn-secondary {
  background: #27ae60;
}

.btn-secondary:hover {
  background: #229954;
}

.btn-danger {
  background: #e74c3c;
}

.btn-danger:hover {
  background: #c0392b;
}

.btn-small {
  padding: 0.25rem 0.5rem;
  font-size: 0.875rem;
}

.muted {
  opacity: 0.5;
}

.sync-method-select {
  padding: 0.5rem;
  border: 1px solid #ddd;
  border-radius: 4px;
  background: white;
}

.sync-info {
  padding: 0.5rem 1rem;
  background: #d4edda;
  border: 1px solid #c3e6cb;
  border-radius: 4px;
  margin-bottom: 1rem;
  display: flex;
  gap: 2rem;
  font-size: 0.875rem;
  color: #155724;
}

.fix-toggle {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.25rem 0.5rem;
  background: #f0f0f0;
  border-radius: 4px;
}

.fix-toggle input[type="checkbox"] {
  cursor: pointer;
}

.offset-control {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  flex-wrap: wrap;
}

.offset-control.disabled {
  opacity: 0.5;
}

.offset-input {
  width: 80px;
  padding: 0.25rem 0.5rem;
  border: 1px solid #ddd;
  border-radius: 4px;
  font-family: monospace;
}

.offset-buttons {
  display: flex;
  gap: 0.25rem;
  align-items: center;
}

.btn-tiny {
  padding: 0.2rem 0.4rem;
  font-size: 0.75rem;
}

.separator {
  margin: 0 0.25rem;
  color: #999;
}

.waveform-container {
  margin-top: 1rem;
  padding: 0.5rem;
  background: #f9f9f9;
  border-radius: 4px;
}

.waveform {
  width: 100%;
  margin-bottom: 0.5rem;
  overflow-x: auto;
  overflow-y: hidden;
}

.waveform-sync-controls {
  display: flex;
  gap: 0.5rem;
  align-items: center;
}

.waveform-info {
  margin-bottom: 0.5rem;
  font-size: 0.875rem;
  color: #666;
}

.offset-label {
  margin-right: 1rem;
  font-family: monospace;
}
</style>